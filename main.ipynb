{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc72c999",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cwd: /content\n",
      "os.path.exists('train.csv'): False\n",
      "abs path for 'train.csv': /content/train.csv\n",
      "listing cwd (first 50 entries): ['.config', 'sample_data']\n",
      "listing /content -> ['.config', 'sample_data']\n",
      "listing /root -> ['.profile', '.bashrc', '.local', '.jupyter', '.keras', '.tmux.conf', '.npm', '.wget-hsts', '.config', '.ipython', '.cache', '.julia', '.launchpadlib']\n",
      "find results (relative):\n",
      " <no results>\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "\n",
    "# Config\n",
    "DATA_DIR = Path(\"/content/kaggle_retina\")  # change if needed\n",
    "TRAIN_DIR = DATA_DIR / \"train\"\n",
    "TEST_DIR = DATA_DIR / \"test\"\n",
    "TRAIN_CSV = DATA_DIR / \"train.csv\"\n",
    "SUBMISSION_PATH = DATA_DIR / \"submission.csv\"  # output\n",
    "BATCH_SIZE = 32\n",
    "IMG_SIZE = 224\n",
    "NUM_EPOCHS = 8\n",
    "LR = 1e-4\n",
    "NUM_WORKERS = 0 # Changed from 4 to 0 to prevent memory issues with DataLoader workers\n",
    "RANDOM_SEED = 42\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# Updated column names to match train.csv\n",
    "LABEL_COL = \"diagnosis\"  # column name in train.csv with the target\n",
    "ID_COL = \"id_code\"       # id column name\n",
    "SUBMISSION_COL = LABEL_COL  # column name in submission; adjust if example differs\n",
    "\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "# Dataset\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, df, images_dir, transforms=None, id_col=ID_COL, label_col=LABEL_COL, label_encoder=None, is_test=False):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.images_dir = Path(images_dir)\n",
    "        self.transforms = transforms\n",
    "        self.id_col = id_col\n",
    "        self.label_col = label_col\n",
    "        self.is_test = is_test\n",
    "        self.label_encoder = label_encoder\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def _open_image(self, img_path):\n",
    "        return Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img_id = str(row[self.id_col])\n",
    "        # try common extensions\n",
    "        for ext in [\"png\", \"jpg\", \"jpeg\"]:\n",
    "            p = self.images_dir / f\"{img_id}.{ext}\"\n",
    "            if p.exists():\n",
    "                img = self._open_image(p)\n",
    "                break\n",
    "        else:\n",
    "            # fallback: if ids are full filenames\n",
    "            p = self.images_dir / img_id\n",
    "            img = self._open_image(p)\n",
    "\n",
    "        if self.transforms:\n",
    "            img = self.transforms(img)\n",
    "\n",
    "        if self.is_test:\n",
    "            return img, img_id\n",
    "\n",
    "        label = row[self.label_col]\n",
    "        # Safe label handling:\n",
    "        # - If a LabelEncoder was used earlier to transform the dataframe, labels are already ints.\n",
    "        # - If labels are strings and a label_encoder is provided, transform them.\n",
    "        # - Otherwise cast to int.\n",
    "        if self.label_encoder is not None:\n",
    "            # avoid re-transforming already-encoded ints\n",
    "            if isinstance(label, (int, np.integer)):\n",
    "                label = int(label)\n",
    "            else:\n",
    "                try:\n",
    "                    label = int(self.label_encoder.transform([str(label)])[0])\n",
    "                except Exception:\n",
    "                    label = int(label)\n",
    "        else:\n",
    "            label = int(label)\n",
    "\n",
    "        return img, label\n",
    "\n",
    "## Read CSV (modified to print diagnostics if the file is missing)\n",
    "try:\n",
    "    train_df = pd.read_csv(TRAIN_CSV)\n",
    "except FileNotFoundError:\n",
    "    print(f\"Could not open {TRAIN_CSV!r}\")\n",
    "    print('cwd:', os.getcwd())\n",
    "    print('TRAIN_CSV absolute path:', os.path.abspath(TRAIN_CSV))\n",
    "    print('TRAIN_CSV exists?:', os.path.exists(TRAIN_CSV))\n",
    "    print('listing cwd (first 50):', os.listdir()[:50])\n",
    "    try:\n",
    "        import subprocess\n",
    "        out = subprocess.check_output(['bash','-lc', f'find . -maxdepth 6 -name \"{TRAIN_CSV.name}\" 2>/dev/null || true'], universal_newlines=True)\n",
    "        print('find (relative) results:\\n', out.strip() or '<no results>')\n",
    "    except Exception as _e:\n",
    "        print('shell find unavailable or failed:', _e)\n",
    "    # If the file is on Google Drive, remind the user:\n",
    "    print('\\nIf you uploaded the file via Colab UI, remember uploads are ephemeral.\\nIf the file is on Google Drive, mount it and use the full path:')\n",
    "    print(\"from google.colab import drive; drive.mount('/content/drive')\")\n",
    "    raise\n",
    "\n",
    "if LABEL_COL not in train_df.columns or ID_COL not in train_df.columns:\n",
    "    raise RuntimeError(f\"Expected columns '{ID_COL}' and '{LABEL_COL}' in {TRAIN_CSV}\")\n",
    "\n",
    "# Encode labels only when necessary (keep numeric labels intact)\n",
    "le = None\n",
    "if not pd.api.types.is_numeric_dtype(train_df[LABEL_COL]):\n",
    "    le = LabelEncoder()\n",
    "    train_df[LABEL_COL] = le.fit_transform(train_df[LABEL_COL].astype(str))\n",
    "    num_classes = len(le.classes_)\n",
    "else:\n",
    "    train_df[LABEL_COL] = train_df[LABEL_COL].astype(int)\n",
    "    num_classes = int(train_df[LABEL_COL].nunique())\n",
    "\n",
    "# Split train/val\n",
    "train_rows, val_rows = train_test_split(train_df, test_size=0.2, random_state=RANDOM_SEED, stratify=train_df[LABEL_COL])\n",
    "\n",
    "# Transforms\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "val_transforms = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Datasets and loaders\n",
    "train_dataset = ImageDataset(train_rows, TRAIN_DIR, transforms=train_transforms, label_encoder=le, is_test=False)\n",
    "val_dataset = ImageDataset(val_rows, TRAIN_DIR, transforms=val_transforms, label_encoder=le, is_test=False)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE*2, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)\n",
    "\n",
    "# Model (transfer learning with ResNet18)\n",
    "model = models.resnet18(pretrained=True)\n",
    "in_features = model.fc.in_features\n",
    "model.fc = nn.Linear(in_features, num_classes)\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.5)\n",
    "\n",
    "# Training loop with checkpointing\n",
    "START_EPOCH = 1\n",
    "best_val_acc = 0.0\n",
    "best_state = None\n",
    "CHECKPOINT_PATH = \"model_checkpoint.pth\"\n",
    "\n",
    "# Load checkpoint if it exists\n",
    "if os.path.exists(CHECKPOINT_PATH):\n",
    "    print(f\"Loading checkpoint from {CHECKPOINT_PATH}\")\n",
    "    checkpoint = torch.load(CHECKPOINT_PATH)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "    START_EPOCH = checkpoint['epoch'] + 1\n",
    "    best_val_acc = checkpoint['best_val_acc']\n",
    "    best_state = checkpoint['model_state_dict'] # Initialize best_state from checkpoint\n",
    "    print(f\"Resuming training from epoch {START_EPOCH} with best_val_acc: {best_val_acc:.4f}\")\n",
    "\n",
    "for epoch in range(START_EPOCH, NUM_EPOCHS + 1):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    loop = tqdm(train_loader, desc=f\"Epoch {epoch}/{NUM_EPOCHS} (train)\", leave=False)\n",
    "    for imgs, labels in loop:\n",
    "        imgs = imgs.to(DEVICE, non_blocking=True)\n",
    "        labels = labels.to(DEVICE, non_blocking=True)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(imgs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * imgs.size(0)\n",
    "        _, preds = outputs.max(1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "        loop.set_postfix(loss=running_loss/total, acc=correct/total)\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in val_loader:\n",
    "            imgs = imgs.to(DEVICE, non_blocking=True)\n",
    "            labels = labels.to(DEVICE, non_blocking=True)\n",
    "            outputs = model(imgs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item() * imgs.size(0)\n",
    "            _, preds = outputs.max(1)\n",
    "            val_correct += (preds == labels).sum().item()\n",
    "            val_total += labels.size(0)\n",
    "\n",
    "    val_acc = val_correct / val_total\n",
    "    val_loss = val_loss / val_total\n",
    "    print(f\"Epoch {epoch}: train_loss={running_loss/total:.4f} train_acc={correct/total:.4f} val_loss={val_loss:.4f} val_acc={val_acc:.4f}\")\n",
    "\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        best_state = model.state_dict().copy()\n",
    "        \n",
    "        checkpoint = {\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'scheduler_state_dict': scheduler.state_dict(),\n",
    "            'best_val_acc': best_val_acc,\n",
    "        }\n",
    "        torch.save(checkpoint, CHECKPOINT_PATH)\n",
    "        print(f\"Saved new best model checkpoint at epoch {epoch} with validation accuracy {best_val_acc:.4f}\")\n",
    "\n",
    "# Load best model (for inference, loads the state_dict of the best model found)\n",
    "if best_state is not None:\n",
    "    model.load_state_dict(best_state)\n",
    "\n",
    "# Inference on test set and create submission\n",
    "# Expect test folder contains files named {id}.jpg (or png)\n",
    "# If there is a sample submission with expected ids, prefer that. Try to read sample if present.\n",
    "test_files = []\n",
    "for p in sorted(TEST_DIR.iterdir()):\n",
    "    if p.suffix.lower() in [\".jpg\", \".jpeg\", \".png\", \".bmp\"]:\n",
    "        test_files.append(p.stem)\n",
    "\n",
    "example_paths = [\"sample_submission.csv\", \"submission.csv\"]\n",
    "for pth in example_paths:\n",
    "    if os.path.exists(pth):\n",
    "        sample = pd.read_csv(pth)\n",
    "        if ID_COL in sample.columns:\n",
    "            test_ids = sample[ID_COL].astype(str).tolist()\n",
    "        else:\n",
    "            test_ids = test_files\n",
    "        break\n",
    "else:\n",
    "    test_ids = test_files\n",
    "\n",
    "# Build test DataFrame\n",
    "test_df = pd.DataFrame({ID_COL: test_ids})\n",
    "test_dataset = ImageDataset(test_df, TEST_DIR, transforms=val_transforms, is_test=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n",
    "\n",
    "model.eval()\n",
    "preds_all = []\n",
    "ids_all = []\n",
    "with torch.no_grad():\n",
    "    for imgs, ids in tqdm(test_loader, desc=\"Predict\"):\n",
    "        imgs = imgs.to(DEVICE)\n",
    "        outputs = model(imgs)\n",
    "        probs = torch.softmax(outputs, dim=1)\n",
    "        preds = probs.argmax(dim=1).cpu().numpy()\n",
    "        preds_all.extend(preds.tolist())\n",
    "        ids_all.extend(ids)\n",
    "\n",
    "# Convert numeric preds back to original labels\n",
    "if le is not None:\n",
    "    pred_labels = le.inverse_transform(preds_all)\n",
    "else:\n",
    "    pred_labels = [int(x) for x in preds_all]\n",
    "\n",
    "submission = pd.DataFrame({ID_COL: ids_all, SUBMISSION_COL: pred_labels})\n",
    "submission.to_csv(SUBMISSION_PATH, index=False)\n",
    "print(f\"Saved submission to {SUBMISSION_PATH}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
